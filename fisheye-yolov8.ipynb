{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7567418,"sourceType":"datasetVersion","datasetId":4405663},{"sourceId":7808531,"sourceType":"datasetVersion","datasetId":4573181}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# === Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n dataset g·ªëc c·ªßa b·∫°n ===\nbase_dir = \"/kaggle/input/fisheye8k/Fisheye8K\"\ntrain_dir = os.path.join(base_dir, \"train\")\nval_dir   = os.path.join(base_dir, \"test\")\n\n# === Th∆∞ m·ª•c output ===\noutput_dir = \"/kaggle/working/dataset_split\"\nimages_dir = os.path.join(output_dir, \"images\")\nlabels_dir = os.path.join(output_dir, \"labels\")\n\nfor d in [\"train\", \"val\"]:\n    os.makedirs(os.path.join(images_dir, d), exist_ok=True)\n    os.makedirs(os.path.join(labels_dir, d), exist_ok=True)\n\n# === L·∫•y to√†n b·ªô ·∫£nh t·ª´ c·∫£ train + val ===\nall_images = []\nfor d in [train_dir, val_dir]:\n    img_path = os.path.join(d, \"images\")\n    for f in os.listdir(img_path):\n        if f.endswith((\".jpg\", \".png\", \".jpeg\")):\n            all_images.append(os.path.join(img_path, f))\n\nprint(\"T·ªïng s·ªë ·∫£nh ban ƒë·∫ßu:\", len(all_images))\n\n# === Shuffle ƒë·ªÉ random ===\nrandom.shuffle(all_images)\n\n# === Chia 80/20 ===\nsplit_idx = int(0.8 * len(all_images))\ntrain_images = all_images[:split_idx]\nval_images   = all_images[split_idx:]\n\ndef copy_files(image_list, subset):\n    for img_path in image_list:\n        file_name = os.path.basename(img_path)\n        label_name = os.path.splitext(file_name)[0] + \".txt\"\n\n        # copy ·∫£nh\n        shutil.copy(img_path, os.path.join(images_dir, subset, file_name))\n\n        # copy nh√£n (n·∫øu c√≥)\n        label_path = img_path.replace(\"images\", \"labels\")\n        label_path = os.path.splitext(label_path)[0] + \".txt\"\n        if os.path.exists(label_path):\n            shutil.copy(label_path, os.path.join(labels_dir, subset, label_name))\n\ncopy_files(train_images, \"train\")\ncopy_files(val_images, \"val\")\n\nprint(f\"Train: {len(train_images)} ·∫£nh\")\nprint(f\"Val: {len(val_images)} ·∫£nh\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import textwrap\n\n# ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file YAML\n# Thay t√™n data.yaml\ndata_yaml_path = '/kaggle/working/data.yaml'\n\nyaml_content = textwrap.dedent(\"\"\"\n    train: /kaggle/working/dataset_split/images/train\n    val: /kaggle/working/dataset_split/images/val\n    nc: 5\n    names: [\"Bus\", \"Bike\", \"Car\", \"Pedestrian\", \"Truck\"]\n\"\"\")\n\n# Ch·ªâ c·∫ßn m·ªôt l·∫ßn ghi file duy nh·∫•t\nwith open(data_yaml_path, 'w') as f:\n    f.write(yaml_content)\n\nprint(f\"‚úÖ ƒê√£ t·∫°o file {data_yaml_path} th√†nh c√¥ng.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T02:43:22.164840Z","iopub.execute_input":"2025-11-02T02:43:22.165365Z","iopub.status.idle":"2025-11-02T02:43:22.169964Z","shell.execute_reply.started":"2025-11-02T02:43:22.165342Z","shell.execute_reply":"2025-11-02T02:43:22.169375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os\n\n# ==============================\n# üöÄ STAGE 1: Training t·ª´ ƒë·∫ßu\n# ==============================\n\nprint(\"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v·ªõi d·ªØ li·ªáu k·∫øt h·ª£p v√† c·∫•u h√¨nh t·ªëi ∆∞u...\")\nmodel = YOLO('yolov8m.pt')\n\nresults = model.train(\n    data='/kaggle/working/data.yaml',\n    epochs=20,\n    imgsz=1280,\n    batch=8,\n\n    # Training strategy\n    lr0=0.005, lrf=0.01,\n    weight_decay=0.0005,\n    patience=10,\n\n    # Augmentation\n    degrees=10,\n    translate=0.1,\n    scale=0.7,\n    perspective=0.0003,\n    mosaic=1.0,\n    mixup=0.15,\n    hsv_h=0.02, hsv_s=0.7, hsv_v=0.4,\n\n    # Inference settings\n    conf=0.25,\n    iou=0.5,\n\n    # Output\n    project='/kaggle/working/yolov8m_training_results_v2',\n    name='stage1'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T02:43:26.315332Z","iopub.execute_input":"2025-11-02T02:43:26.315630Z","iopub.status.idle":"2025-11-02T07:50:25.363047Z","shell.execute_reply.started":"2025-11-02T02:43:26.315609Z","shell.execute_reply":"2025-11-02T07:50:25.362162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\nimport os\n\n# üöÄ Resume Stage 1 t·ª´ checkpoint cu·ªëi c√πng (last.pt)\nmodel = YOLO('/kaggle/working/yolov8m_training_results_v2/stage1/weights/last.pt')\n\nprint(\"üöÄ Ti·∫øp t·ª•c hu·∫•n luy·ªán Stage 1 t·ª´ last.pt...\")\nresults = model.train(\n    resume=True\n)\n\nprint(\"üéâ Qu√° tr√¨nh hu·∫•n luy·ªán Stage 1 ƒë√£ ƒë∆∞·ª£c resume th√†nh c√¥ng!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T08:03:19.840334Z","iopub.execute_input":"2025-11-02T08:03:19.840720Z","iopub.status.idle":"2025-11-02T08:03:23.889470Z","shell.execute_reply.started":"2025-11-02T08:03:19.840684Z","shell.execute_reply":"2025-11-02T08:03:23.882816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ==============================\n# üöÄ STAGE 2: Fine-tune t·ª´ Best\n# ==============================\nprint(\"üî• B·∫Øt ƒë·∫ßu Stage 2 Fine-tuning t·ª´ best.pt...\")\n\nbest_model_path = \"/kaggle/working/yolov8m_training_results_v2/stage1/weights/best.pt\"\nmodel = YOLO(best_model_path)\n\nresults = model.train(\n    data='/kaggle/working/data.yaml',\n    epochs=30,\n    imgsz=1280,\n    batch=8,\n\n    # Training strategy (LR gi·∫£m ƒë·ªÉ fine-tune ·ªïn ƒë·ªãnh)\n    lr0=0.001,\n    lrf=0.005,\n    weight_decay=0.0005,\n    patience=10,\n\n     # Augmentation (gi·∫£m nh·∫π so v·ªõi Stage 1)\n    degrees=5,         # xoay √≠t h∆°n\n    translate=0.05,    # d·ªãch chuy·ªÉn √≠t h∆°n\n    scale=0.5,         # thu ph√≥ng v·ª´a ph·∫£i\n    perspective=0.0002,\n    mosaic=0.5,        # gi·∫£m mosaic ƒë·ªÉ ·∫£nh t·ª± nhi√™n h∆°n\n    mixup=0.05,        # gi·∫£m mixup, tr√°nh ·∫£nh b·ªã qu√° nhi·ªÖu\n    hsv_h=0.02,\n    hsv_s=0.5,         # gi·∫£m saturation\n    hsv_v=0.3,         # gi·∫£m ƒë·ªô s√°ng\n\n\n    # Inference settings\n    conf=0.25,\n    iou=0.5,\n\n    # Output\n    project='/kaggle/working/yolov8m_training_results_v2',\n    name='stage2'\n)\n\nprint(\"üéâ Stage 2 hu·∫•n luy·ªán ƒë√£ ho√†n t·∫•t!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T08:25:11.792205Z","iopub.execute_input":"2025-11-02T08:25:11.792794Z","execution_failed":"2025-11-02T14:32:31.141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# 1. THAY ƒê·ªîI ƒê∆Ø·ªúNG D·∫™N N√ÄY cho ƒë√∫ng v·ªõi file c·ªßa b·∫°n\npath_to_last_checkpoint = '/kaggle/working/yolov8m_training_results_v2/stage2/weights/last.pt'\n\n# 2. T·∫£i m√¥ h√¨nh tr·ª±c ti·∫øp t·ª´ checkpoint cu·ªëi c√πng\nmodel = YOLO(path_to_last_checkpoint)\n\n# 3. Ch·∫°y l·ªánh resume v·ªõi compile=True\nprint(\"üöÄ B·∫Øt ƒë·∫ßu ti·∫øp t·ª•c qu√° tr√¨nh hu·∫•n luy·ªán Fisheye...\")\nresults = model.train(\n    resume=True,\n)\n\nprint(\"üéâ Qu√° tr√¨nh hu·∫•n luy·ªán ƒë√£ ho√†n t·∫•t!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T14:52:23.272591Z","iopub.execute_input":"2025-11-02T14:52:23.272882Z","iopub.status.idle":"2025-11-02T14:52:27.075316Z","shell.execute_reply.started":"2025-11-02T14:52:23.272856Z","shell.execute_reply":"2025-11-02T14:52:27.074223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nimport torch\nimport numpy as np\nimport random\nfrom ultralytics import YOLO\nfrom tqdm import tqdm\nfrom PIL import Image # Th√™m th∆∞ vi·ªán ƒë·ªÉ x·ª≠ l√Ω v√† l∆∞u ·∫£nh\n\n# --- B∆Ø·ªöC 1: C·∫§U H√åNH ---\nbest_model_path = '/kaggle/working/yolov8m_training_results_v2/stage2/weights/best.pt'\ntest_images_folder = '/kaggle/working/dataset_split/images/val'\nground_truth_json_path = '/kaggle/input/fisheye8k/Fisheye8K/test/test.json'\n# --- THAY ƒê·ªîI: Th√™m ƒë∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u ·∫£nh k·∫øt qu·∫£ ---\noutput_visualization_folder = '/kaggle/working/prediction_021025'\n\nIOU_THRESHOLD = 0.7\nCONFIDENCE_THRESHOLD = 0.25\n\n# --- B∆Ø·ªöC 2: H√ÄM H·ªñ TR·ª¢ ---\ndef calculate_iou(boxA, boxB):\n    xA = max(boxA[0], boxB[0]); yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2]); yB = min(boxA[3], boxB[3])\n    interArea = max(0, xB - xA) * max(0, yB - yA)\n    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n    iou = interArea / float(boxAArea + boxBArea - interArea)\n    return iou\n\ndef load_ground_truth(json_path):\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    images_map = {img['id']: img['file_name'] for img in data['images']}\n    ground_truths = {}\n    total_gt_objects = 0\n    for ann in data['annotations']:\n        total_gt_objects += 1\n        filename = images_map[ann['image_id']]\n        if filename not in ground_truths:\n            ground_truths[filename] = []\n        bbox = ann['bbox']\n        gt_box = [bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]]\n        ground_truths[filename].append({'class_id': ann['category_id'], 'bbox': gt_box})\n    return ground_truths, total_gt_objects\n\n# --- B∆Ø·ªöC 3: TH·ª∞C THI ---\n# T·∫£i model\nprint(\"üöÄ ƒêang t·∫£i model...\")\nmodel = YOLO(best_model_path)\n\n# ƒê·ªçc d·ªØ li·ªáu ground truth\nprint(\"üìö ƒêang ƒë·ªçc d·ªØ li·ªáu Ground Truth t·ª´ test.json...\")\nground_truths, total_ground_truth_objects = load_ground_truth(ground_truth_json_path)\n\n# L·∫•y to√†n b·ªô ·∫£nh test\nprint(\"üìù L·∫•y to√†n b·ªô ·∫£nh t·ª´ th∆∞ m·ª•c test...\")\nall_image_files = [os.path.join(test_images_folder, f) for f in os.listdir(test_images_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n# Ch·∫°y d·ª± ƒëo√°n tr√™n to√†n b·ªô t·∫≠p ·∫£nh\nprint(f\"üîÆ B·∫Øt ƒë·∫ßu ch·∫°y d·ª± ƒëo√°n tr√™n to√†n b·ªô {len(all_image_files)} ·∫£nh...\")\nresults_list = []\nfor img_path in tqdm(all_image_files, desc=\"ƒêang d·ª± ƒëo√°n\"):\n    result = model.predict(source=img_path, conf=CONFIDENCE_THRESHOLD, verbose=False)\n    results_list.append(result[0])\n\n# --- THAY ƒê·ªîI: L∆ØU 10 ·∫¢NH K·∫æT QU·∫¢ NG·∫™U NHI√äN ---\nprint(\"\\nüñºÔ∏è ƒêang l∆∞u 10 ·∫£nh k·∫øt qu·∫£ ng·∫´u nhi√™n...\")\n# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i\nos.makedirs(output_visualization_folder, exist_ok=True)\n# Ch·ªçn ng·∫´u nhi√™n 10 k·∫øt qu·∫£\nrandom_results_to_show = random.sample(results_list, min(10, len(results_list)))\nfor result in random_results_to_show:\n    # result.plot() tr·∫£ v·ªÅ ·∫£nh d∆∞·ªõi d·∫°ng m·∫£ng numpy (BGR)\n    plotted_image_bgr = result.plot()\n    # Chuy·ªÉn t·ª´ BGR sang RGB ƒë·ªÉ PIL c√≥ th·ªÉ x·ª≠ l√Ω ƒë√∫ng m√†u\n    plotted_image_rgb = plotted_image_bgr[..., ::-1]\n    # T·∫°o ƒë·ªëi t∆∞·ª£ng ·∫£nh t·ª´ m·∫£ng\n    img_to_save = Image.fromarray(plotted_image_rgb)\n    # L∆∞u ·∫£nh\n    output_path = os.path.join(output_visualization_folder, os.path.basename(result.path))\n    img_to_save.save(output_path)\nprint(f\"‚úÖ ƒê√£ l∆∞u ·∫£nh v√†o th∆∞ m·ª•c: {output_visualization_folder}\")\n\n# Kh·ªüi t·∫°o c√°c bi·∫øn ƒë·∫øm\ntotal_true_positives = 0\ntotal_false_positives = 0\n\nprint(\"\\nüîç B·∫Øt ƒë·∫ßu so kh·ªõp d·ª± ƒëo√°n v√† Ground Truth...\")\n# V√≤ng l·∫∑p so kh·ªõp\nfor result in tqdm(results_list, desc=\"ƒêang x·ª≠ l√Ω ·∫£nh\"):\n    filename = os.path.basename(result.path)\n    pred_boxes = result.boxes.xyxy.cpu().numpy()\n    pred_classes = result.boxes.cls.cpu().numpy().astype(int)\n    gt_objects = ground_truths.get(filename, [])\n\n    if not gt_objects:\n        total_false_positives += len(pred_boxes)\n        continue\n\n    gt_boxes_for_img = [item['bbox'] for item in gt_objects]\n    gt_classes_for_img = [item['class_id'] for item in gt_objects]\n    gt_matched = [False] * len(gt_boxes_for_img)\n\n    # S·∫Øp x·∫øp c√°c d·ª± ƒëo√°n theo ƒë·ªô tin c·∫≠y gi·∫£m d·∫ßn\n    sorted_indices = np.argsort(-result.boxes.conf.cpu().numpy())\n\n    for i in sorted_indices:\n        pred_box = pred_boxes[i]\n        pred_class = pred_classes[i]\n        best_iou = 0\n        best_gt_idx = -1\n\n        for j in range(len(gt_boxes_for_img)):\n            if gt_classes_for_img[j] == pred_class and not gt_matched[j]:\n                iou = calculate_iou(pred_box, gt_boxes_for_img[j])\n                if iou > best_iou:\n                    best_iou = iou\n                    best_gt_idx = j\n\n        if best_iou >= IOU_THRESHOLD:\n            gt_matched[best_gt_idx] = True\n            total_true_positives += 1\n        else:\n            total_false_positives += 1\n\n# --- B∆Ø·ªöC 4: T√çNH TO√ÅN V√Ä IN K·∫æT QU·∫¢ ---\ntotal_false_negatives = total_ground_truth_objects - total_true_positives\n\ntry:\n    precision = total_true_positives / (total_true_positives + total_false_positives)\nexcept ZeroDivisionError:\n    precision = 0.0\n\ntry:\n    recall = total_true_positives / (total_true_positives + total_false_negatives)\nexcept ZeroDivisionError:\n    recall = 0.0\n\ntry:\n    f1_score = 2 * (precision * recall) / (precision + recall)\nexcept ZeroDivisionError:\n    f1_score = 0.0\n\nprint(\"\\n--- K·∫æT QU·∫¢ ƒê√ÅNH GI√Å TR√äN TO√ÄN B·ªò T·∫¨P TEST ---\")\nprint(f\"T·ªïng s·ªë v·∫≠t th·ªÉ c√≥ th·∫≠t: {total_ground_truth_objects}\")\nprint(\"------------------------------------\")\nprint(f\"True Positives:    {total_true_positives}\")\nprint(f\"False Positives:   {total_false_positives}\")\nprint(f\"False Negatives:    {total_false_negatives}\")\nprint(\"------------------------------------\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall:    {recall:.4f}\")\nprint(f\"F1-Score: {f1_score:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nfrom pathlib import Path\nfrom ultralytics import YOLO\nfrom tqdm.notebook import tqdm\nimport gc\n\n# ==============================================================================\n# 1. C·∫§U H√åNH\n# ==============================================================================\nCONFIG = {\n    \"project_root\": \"/kaggle/working/results\",\n    \"test_image_dirs\": [\n        \"/kaggle/input/fisheye1keval/images/images\",\n        \"/kaggle/input/fisheye1keval/images1/images1\"\n    ],\n    \"model_for_prediction\": \"/kaggle/working/yolov8m_training_results_v2/stage2/weights/best.pt\",\n    \"confidence_threshold\": 0.25,\n    \"img_size\": 1280,\n    \"batch_size\": 100\n}\n\n# ==============================================================================\n# 2. H√ÄM CH·ª®C NƒÇNG\n# ==============================================================================\ndef get_image_id(img_name: str) -> int | None:\n    try:\n        img_name = img_name.split('.png')[0]\n        sceneList = ['M', 'A', 'E', 'N']\n        cameraIndx = int(img_name.split('_')[0].split('camera')[1])\n        sceneIndx = sceneList.index(img_name.split('_')[1])\n        frameIndx = int(img_name.split('_')[2])\n        imageId = int(str(cameraIndx) + str(sceneIndx) + str(frameIndx))\n        return imageId\n    except (IndexError, ValueError):\n        return None\n\nCATEGORY_MAP = {0:0, 1:1, 2:2, 3:3, 4:4}\n\n# ==============================================================================\n# 3. KH·ªêI ƒêI·ªÄU KHI·ªÇN CH√çNH\n# ==============================================================================\nif __name__ == \"__main__\":\n\n    PROJECT_ROOT = Path(CONFIG[\"project_root\"])\n    TEMP_OUTPUT_FILE = PROJECT_ROOT / \"temp_results.jsonl\"\n    SUBMISSION_FILE_PATH = PROJECT_ROOT / \"submission.json\"\n\n    # --- A. Ki·ªÉm tra ti·∫øn tr√¨nh c≈© ---\n    processed_image_ids = set()\n    if TEMP_OUTPUT_FILE.exists():\n        with open(TEMP_OUTPUT_FILE, 'r') as f:\n            for line in f:\n                try:\n                    processed_image_ids.add(json.loads(line)['image_id'])\n                except json.JSONDecodeError:\n                    continue\n        print(f\"üîç ƒê√£ t√¨m th·∫•y file t·∫°m. B·ªè qua {len(processed_image_ids)} ·∫£nh ƒë√£ x·ª≠ l√Ω.\")\n\n    # --- B. Gom v√† l·ªçc ·∫£nh ---\n    all_test_images = [p for folder in CONFIG[\"test_image_dirs\"] for p in Path(folder).glob(\"*.png\")]\n    images_to_process = [p for p in all_test_images if get_image_id(p.name) not in processed_image_ids]\n\n    if not images_to_process:\n        print(\"‚úÖ T·∫•t c·∫£ ·∫£nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω.\")\n    else:\n        print(f\"üî• C·∫ßn x·ª≠ l√Ω {len(images_to_process)} ·∫£nh m·ªõi.\")\n        model = YOLO(CONFIG[\"model_for_prediction\"])\n\n        batch_size = CONFIG[\"batch_size\"]\n        with open(TEMP_OUTPUT_FILE, 'a') as f:\n            for i in tqdm(range(0, len(images_to_process), batch_size), desc=\"ƒêang x·ª≠ l√Ω c√°c l√¥\"):\n                batch_images = images_to_process[i : i + batch_size]\n                if not batch_images:\n                    continue\n\n                results = model.predict(\n                    source=[str(p) for p in batch_images],\n                    stream=False,\n                    imgsz=CONFIG[\"img_size\"],\n                    conf=CONFIG[\"confidence_threshold\"],\n                    iou=0.5,\n                    max_det=1000,\n                    device=0\n                )\n\n                for r in results:\n                    image_id = get_image_id(Path(r.path).name)\n                    if image_id is None:\n                        continue\n                    for box in r.boxes:\n                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n                        width, height = float(x2 - x1), float(y2 - y1)\n                        category_id = CATEGORY_MAP.get(int(box.cls), int(box.cls))\n                        detection = {\n                            \"image_id\": image_id,\n                            \"category_id\": category_id,\n                            \"bbox\": [float(x1), float(y1), width, height],\n                            \"score\": float(box.conf)\n                        }\n                        f.write(json.dumps(detection) + '\\n')\n\n                del results\n                gc.collect()\n        print(\"‚úÖ D·ª± ƒëo√°n ho√†n t·∫•t!\")\n\n    # --- D. T·∫°o file submission cu·ªëi c√πng ---\n    print(\"\\nüîÑ T·ªïng h·ª£p file submission.json...\")\n    all_detections = []\n    with open(TEMP_OUTPUT_FILE, 'r') as f:\n        for line in f:\n            try:\n                all_detections.append(json.loads(line))\n            except json.JSONDecodeError:\n                continue\n\n    with open(SUBMISSION_FILE_PATH, 'w') as f:\n        json.dump(all_detections, f, indent=4)\n\n    print(f\"üéâ Ho√†n t·∫•t! File submission ƒë∆∞·ª£c t·∫°o t·∫°i: {SUBMISSION_FILE_PATH}\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}